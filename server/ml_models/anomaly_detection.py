import numpy as np
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import joblib

class AnomalyDetector:
    """
    Ph√°t hi·ªán c√°c b·∫•t th∆∞·ªùng:
    1. Sensor drift (c·∫£m bi·∫øn tr√¥i gi√° tr·ªã)
    2. Pump malfunction (m√°y b∆°m ho·∫°t ƒë·ªông b·∫•t th∆∞·ªùng)
    3. Sudden moisture drop (ƒë·ªô ·∫©m gi·∫£m ƒë·ªôt ng·ªôt)
    4. System disconnection (m·∫•t k·∫øt n·ªëi)
    5. Water leak (r√≤ r·ªâ n∆∞·ªõc)
    """
    
    def __init__(self, db_path='tuoi.db'):
        self.db_path = db_path
        self.model = None
        self.scaler = StandardScaler()
        
        # Thresholds
        self.MOISTURE_DROP_THRESHOLD = 10  # % drop in 1 hour
        self.MOISTURE_SPIKE_THRESHOLD = 15  # % spike in 1 hour
        self.PUMP_MAX_RUNTIME = 30  # minutes continuous
        self.DISCONNECT_THRESHOLD = 300  # seconds
        
    def load_recent_data(self, hours=24):
        """Load d·ªØ li·ªáu g·∫ßn ƒë√¢y"""
        con = sqlite3.connect(self.db_path)
        cutoff = (datetime.now() - timedelta(hours=hours)).isoformat()
        
        query = """
        SELECT ts, soil, pump, auto, wifi_connected, wifi_rssi
        FROM logs
        WHERE ts >= ?
        ORDER BY ts ASC
        """
        
        df = pd.read_sql_query(query, con, params=(cutoff,))
        con.close()
        
        if len(df) > 0:
            df['ts'] = pd.to_datetime(df['ts'])
        
        return df
    
    def detect(self):
        """
        Ch·∫°y t·∫•t c·∫£ c√°c detection methods
        
        Returns:
            List of anomalies detected
        """
        anomalies = []
        
        # Load data
        df = self.load_recent_data(hours=24)
        
        if len(df) < 10:
            return [{
                'type': 'insufficient_data',
                'severity': 'INFO',
                'message': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch (< 10 records)',
                'timestamp': datetime.now().isoformat()
            }]
        
        # Run detection methods
        anomalies.extend(self.detect_sensor_drift(df))
        anomalies.extend(self.detect_moisture_anomalies(df))
        anomalies.extend(self.detect_pump_issues(df))
        anomalies.extend(self.detect_disconnections(df))
        anomalies.extend(self.detect_water_leak(df))
        
        print(f"üîç Anomaly Detection: Found {len(anomalies)} issues")
        for a in anomalies:
            print(f"   [{a['severity']}] {a['type']}: {a['message']}")
        
        return anomalies
    
    def detect_sensor_drift(self, df):
        """
        Ph√°t hi·ªán sensor drift (c·∫£m bi·∫øn tr√¥i gi√° tr·ªã)
        
        Method: Check n·∫øu gi√° tr·ªã stuck ·ªü m·ªôt m·ª©c qu√° l√¢u
        """
        anomalies = []
        
        if len(df) < 20:
            return anomalies
        
        # Get last 20 readings
        recent = df.tail(20)
        
        # Check if values are too constant (variance too low)
        soil_std = recent['soil'].std()
        
        if soil_std < 0.5:  # Variance < 0.5% trong 20 readings
            anomalies.append({
                'type': 'sensor_drift',
                'severity': 'WARNING',
                'message': f'C·∫£m bi·∫øn ƒë·ªô ·∫©m c√≥ th·ªÉ b·ªã l·ªói (variance qu√° th·∫•p: {soil_std:.2f}%)',
                'timestamp': datetime.now().isoformat(),
                'details': {
                    'std_dev': soil_std,
                    'mean': recent['soil'].mean()
                }
            })
        
        # Check if stuck at exactly 0% or 100%
        if recent['soil'].min() == 0 and recent['soil'].max() == 0:
            anomalies.append({
                'type': 'sensor_failure',
                'severity': 'CRITICAL',
                'message': 'C·∫£m bi·∫øn ƒë·ªô ·∫©m b√°o 0% li√™n t·ª•c - c√≥ th·ªÉ b·ªã ƒë·ª©t d√¢y',
                'timestamp': datetime.now().isoformat()
            })
        
        if recent['soil'].min() == 100 and recent['soil'].max() == 100:
            anomalies.append({
                'type': 'sensor_failure',
                'severity': 'CRITICAL',
                'message': 'C·∫£m bi·∫øn ƒë·ªô ·∫©m b√°o 100% li√™n t·ª•c - c√≥ th·ªÉ b·ªã ng·∫≠p n∆∞·ªõc',
                'timestamp': datetime.now().isoformat()
            })
        
        return anomalies
    
    def detect_moisture_anomalies(self, df):
        """
        Ph√°t hi·ªán bi·∫øn ƒë·ªông ƒë·ªô ·∫©m b·∫•t th∆∞·ªùng
        """
        anomalies = []
        
        if len(df) < 2:
            return anomalies
        
        # Calculate hourly changes
        df_sorted = df.sort_values('ts')
        df_sorted['soil_diff'] = df_sorted['soil'].diff()
        
        # Sudden drop
        max_drop = df_sorted['soil_diff'].min()
        if max_drop < -self.MOISTURE_DROP_THRESHOLD:
            idx = df_sorted['soil_diff'].idxmin()
            anomalies.append({
                'type': 'sudden_moisture_drop',
                'severity': 'WARNING',
                'message': f'ƒê·ªô ·∫©m gi·∫£m ƒë·ªôt ng·ªôt {abs(max_drop):.1f}% - ki·ªÉm tra r√≤ r·ªâ',
                'timestamp': df_sorted.loc[idx, 'ts'].isoformat(),
                'details': {
                    'drop_amount': abs(max_drop),
                    'from': df_sorted.loc[idx-1, 'soil'] if idx > 0 else None,
                    'to': df_sorted.loc[idx, 'soil']
                }
            })
        
        # Sudden spike (kh√¥ng t·ª± nhi√™n)
        max_spike = df_sorted['soil_diff'].max()
        if max_spike > self.MOISTURE_SPIKE_THRESHOLD:
            idx = df_sorted['soil_diff'].idxmax()
            
            # Check if pump was on (spike is expected)
            pump_was_on = df_sorted.loc[idx, 'pump'] == 1
            
            if not pump_was_on:
                anomalies.append({
                    'type': 'unexplained_moisture_spike',
                    'severity': 'WARNING',
                    'message': f'ƒê·ªô ·∫©m tƒÉng ƒë·ªôt ng·ªôt {max_spike:.1f}% khi m√°y b∆°m t·∫Øt',
                    'timestamp': df_sorted.loc[idx, 'ts'].isoformat(),
                    'details': {
                        'spike_amount': max_spike,
                        'pump_state': 'OFF'
                    }
                })
        
        return anomalies
    
    def detect_pump_issues(self, df):
        """
        Ph√°t hi·ªán v·∫•n ƒë·ªÅ m√°y b∆°m
        """
        anomalies = []
        
        # Find continuous pump ON periods
        df_sorted = df.sort_values('ts')
        df_sorted['pump_change'] = df_sorted['pump'].diff().fillna(0)
        
        # Get ON periods
        on_starts = df_sorted[df_sorted['pump_change'] == 1].index
        on_ends = df_sorted[df_sorted['pump_change'] == -1].index
        
        for start_idx in on_starts:
            # Find corresponding end
            end_candidates = on_ends[on_ends > start_idx]
            
            if len(end_candidates) == 0:
                # Pump still ON
                duration = (datetime.now() - df_sorted.loc[start_idx, 'ts']).total_seconds() / 60
            else:
                end_idx = end_candidates[0]
                duration = (df_sorted.loc[end_idx, 'ts'] - df_sorted.loc[start_idx, 'ts']).total_seconds() / 60
            
            # Check if duration exceeds threshold
            if duration > self.PUMP_MAX_RUNTIME:
                anomalies.append({
                    'type': 'pump_long_runtime',
                    'severity': 'WARNING',
                    'message': f'M√°y b∆°m ch·∫°y li√™n t·ª•c {duration:.1f} ph√∫t (v∆∞·ª£t {self.PUMP_MAX_RUNTIME} ph√∫t)',
                    'timestamp': df_sorted.loc[start_idx, 'ts'].isoformat(),
                    'details': {
                        'duration_minutes': duration
                    }
                })
        
        # Check pump effectiveness
        # If pump ON but moisture not increasing ‚Üí pump issue or leak
        pump_on_periods = df_sorted[df_sorted['pump'] == 1]
        if len(pump_on_periods) > 5:
            soil_change = pump_on_periods['soil'].iloc[-1] - pump_on_periods['soil'].iloc[0]
            
            if soil_change < 2:  # ƒê·ªô ·∫©m tƒÉng < 2% sau b∆°m
                anomalies.append({
                    'type': 'pump_ineffective',
                    'severity': 'CRITICAL',
                    'message': 'M√°y b∆°m ho·∫°t ƒë·ªông nh∆∞ng ƒë·ªô ·∫©m kh√¥ng tƒÉng - ki·ªÉm tra m√°y b∆°m/ƒë∆∞·ªùng ·ªëng',
                    'timestamp': pump_on_periods.iloc[-1]['ts'].isoformat(),
                    'details': {
                        'soil_change': soil_change
                    }
                })
        
        return anomalies
    
    def detect_disconnections(self, df):
        """
        Ph√°t hi·ªán m·∫•t k·∫øt n·ªëi
        """
        anomalies = []
        
        # Check last update time
        if len(df) > 0:
            last_update = df['ts'].max()
            time_since_update = (datetime.now() - last_update).total_seconds()
            
            if time_since_update > self.DISCONNECT_THRESHOLD:
                anomalies.append({
                    'type': 'system_disconnected',
                    'severity': 'CRITICAL',
                    'message': f'M·∫•t k·∫øt n·ªëi v·ªõi ESP32 ({time_since_update/60:.1f} ph√∫t)',
                    'timestamp': datetime.now().isoformat(),
                    'details': {
                        'last_update': last_update.isoformat(),
                        'seconds_ago': time_since_update
                    }
                })
        
        # Check WiFi signal quality
        recent = df.tail(10)
        if len(recent) > 0:
            avg_rssi = recent['wifi_rssi'].mean()
            
            if avg_rssi < -80:  # Very weak signal
                anomalies.append({
                    'type': 'weak_wifi_signal',
                    'severity': 'WARNING',
                    'message': f'T√≠n hi·ªáu WiFi y·∫øu (RSSI: {avg_rssi:.0f} dBm)',
                    'timestamp': datetime.now().isoformat(),
                    'details': {
                        'rssi': avg_rssi
                    }
                })
        
        return anomalies
    
    def detect_water_leak(self, df):
        """
        Ph√°t hi·ªán r√≤ r·ªâ n∆∞·ªõc
        
        Logic: ƒê·ªô ·∫©m gi·∫£m nhanh b·∫•t th∆∞·ªùng khi m√°y b∆°m t·∫Øt
        """
        anomalies = []
        
        if len(df) < 10:
            return anomalies
        
        # Get periods when pump is OFF
        df_sorted = df.sort_values('ts')
        pump_off = df_sorted[df_sorted['pump'] == 0].copy()
        
        if len(pump_off) > 5:
            # Calculate rate of moisture decrease
            pump_off['time_diff'] = pump_off['ts'].diff().dt.total_seconds() / 3600  # hours
            pump_off['moisture_rate'] = pump_off['soil'].diff() / pump_off['time_diff']
            
            # Normal evaporation: -1 to -3% per hour
            # Leak: > -5% per hour
            abnormal_rates = pump_off[pump_off['moisture_rate'] < -5]
            
            if len(abnormal_rates) > 0:
                worst = abnormal_rates['moisture_rate'].min()
                anomalies.append({
                    'type': 'possible_water_leak',
                    'severity': 'CRITICAL',
                    'message': f'ƒê·ªô ·∫©m gi·∫£m qu√° nhanh ({worst:.1f}%/h) khi m√°y b∆°m t·∫Øt - nghi r√≤ r·ªâ',
                    'timestamp': datetime.now().isoformat(),
                    'details': {
                        'rate_per_hour': worst
                    }
                })
        
        return anomalies
    
    def train_isolation_forest(self):
        """
        Train Isolation Forest model cho general anomaly detection
        (Advanced - c√≥ th·ªÉ b·ªè qua n·∫øu ch∆∞a ƒë·ªß data)
        """
        df = self.load_recent_data(hours=24*30)  # 30 days
        
        if len(df) < 100:
            print("‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ train Isolation Forest")
            return
        
        # Feature engineering
        df['hour'] = df['ts'].dt.hour
        df['soil_rolling_mean'] = df['soil'].rolling(window=5).mean()
        df['soil_rolling_std'] = df['soil'].rolling(window=5).std()
        
        features = ['soil', 'pump', 'wifi_rssi', 'hour', 
                   'soil_rolling_mean', 'soil_rolling_std']
        
        X = df[features].dropna()
        
        # Train model
        self.model = IsolationForest(
            contamination=0.05,  # Expect 5% anomalies
            random_state=42
        )
        
        X_scaled = self.scaler.fit_transform(X)
        self.model.fit(X_scaled)
        
        # Save model
        joblib.dump(self.model, 'models/anomaly_detector.pkl')
        joblib.dump(self.scaler, 'models/anomaly_scaler.pkl')
        
        print("‚úÖ Isolation Forest model trained and saved!")


# ============================================
# USAGE EXAMPLE
# ============================================

if __name__ == "__main__":
    detector = AnomalyDetector(db_path='tuoi.db')
    
    # Detect anomalies
    anomalies = detector.detect()
    
    # Print results
    print(f"\nüìä Detection Summary: {len(anomalies)} anomalies found")
    
    for anomaly in anomalies:
        severity_icon = {
            'INFO': '‚ÑπÔ∏è',
            'WARNING': '‚ö†Ô∏è',
            'CRITICAL': 'üö®'
        }.get(anomaly['severity'], '‚ùì')
        
        print(f"\n{severity_icon} {anomaly['type'].upper()}")
        print(f"   Message: {anomaly['message']}")
        print(f"   Time: {anomaly['timestamp']}")
        if 'details' in anomaly:
            print(f"   Details: {anomaly['details']}")